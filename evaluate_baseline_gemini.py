#!/usr/bin/env python3
"""
ê¸°ë³¸ Gemini 2.5 Flash ëª¨ë¸ë¡œ í‰ê°€ (ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥ ì¸¡ì •)

íŒŒì¸íŠœë‹ëœ ëª¨ë¸ê³¼ ë¹„êµí•˜ê¸° ìœ„í•œ ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.
"""

import os
import json
import time
import re
from datetime import datetime
from typing import List, Dict, Tuple
import vertexai
from vertexai.generative_models import GenerativeModel

class BaselineGeminiEvaluator:
    def __init__(self, project_id: str, location: str = "us-central1"):
        """
        ê¸°ë³¸ Gemini ëª¨ë¸ í‰ê°€ì ì´ˆê¸°í™”
        
        Args:
            project_id: Google Cloud í”„ë¡œì íŠ¸ ID
            location: Vertex AI ì§€ì—­
        """
        self.project_id = project_id
        self.location = location
        
        # Vertex AI ì´ˆê¸°í™”
        vertexai.init(project=project_id, location=location)
        
        # ê¸°ë³¸ Gemini 2.5 Flash ëª¨ë¸ ë¡œë“œ
        try:
            # ìˆ˜ì–´ ë²ˆì—­ì— íŠ¹í™”ëœ ì‹œìŠ¤í…œ ì¸ìŠ¤íŠ¸ëŸ­ì…˜
            system_instruction = """ë‹¹ì‹ ì€ í•œêµ­ì–´ë¥¼ í•œêµ­ ìˆ˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 

ì£¼ì–´ì§„ í•œêµ­ì–´ ë¬¸ì¥ì„ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ ìˆ˜ì–´ í‘œê¸°ë²•ìœ¼ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. 

ë²ˆì—­ ê·œì¹™:
1. ë‹¨ì–´ëŠ” '+'ë¡œ ì—°ê²°í•©ë‹ˆë‹¤
2. ê³ ìœ ëª…ì‚¬ë‚˜ ìˆ«ìëŠ” {}ë¡œ ê°ìŒ‰ë‹ˆë‹¤
3. ìˆ˜ì–´ ë¬¸ë²•ì— ë§ê²Œ ì–´ìˆœì„ ì¡°ì •í•©ë‹ˆë‹¤
4. ê°„ê²°í•˜ê³  ëª…í™•í•œ í‘œí˜„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤

ì˜ˆì‹œ:
- "ì•ˆë…•í•˜ì„¸ìš”" â†’ "ì•ˆë…•+ì¸ì‚¬"
- "ë°±ë ¹ë„ëŠ” 1ë…„ì— 100ì¼ì€ ê¸°ë³¸ì ìœ¼ë¡œ í•´ë¬´ê°€ ë¼ì§€ ì•Šì•„?" â†’ "{ë°±ë ¹ë„}+{1}+ë…„+{100}ì¼+ê¸°ë³¸+í•´ë¬´+ì—†ë‹¤"

ë²ˆì—­ ê²°ê³¼ë§Œ ì¶œë ¥í•˜ê³  ì„¤ëª…ì€ ìƒëµí•˜ì„¸ìš”."""

            self.model = GenerativeModel(
                model_name="gemini-2.5-flash",
                system_instruction=system_instruction
            )
            print(f"âœ… ê¸°ë³¸ Gemini 2.5 Flash ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def translate_to_sign(self, korean_text: str, temperature: float = 0.1) -> str:
        """
        í•œêµ­ì–´ ë¬¸ì¥ì„ ìˆ˜ì–´ë¡œ ë²ˆì—­
        
        Args:
            korean_text: ë²ˆì—­í•  í•œêµ­ì–´ ë¬¸ì¥
            temperature: ìƒì„± ì˜¨ë„ (ê¸°ë³¸ê°’: 0.1)
            
        Returns:
            ìˆ˜ì–´ ë²ˆì—­ ê²°ê³¼
        """
        try:
            # ìƒì„± ì„¤ì •
            generation_config = {
                "temperature": temperature,
                "max_output_tokens": 200,
                "top_p": 0.8,
                "top_k": 40
            }
            
            response = self.model.generate_content(
                korean_text,
                generation_config=generation_config
            )
            
            # ì‘ë‹µì—ì„œ ìˆ˜ì–´ ë²ˆì—­ ë¶€ë¶„ë§Œ ì¶”ì¶œ
            text = response.text.strip()
            
            # "+" í¬í•¨ëœ ë²ˆì—­ ê²°ê³¼ ì¶”ì¶œ (ê°„ë‹¨í•œ í›„ì²˜ë¦¬)
            lines = text.split('\n')
            for line in lines:
                line = line.strip()
                # "+" ë¬¸ìê°€ í¬í•¨ëœ ë¼ì¸ì„ ì°¾ìŒ
                if '+' in line and len(line.split('+')) >= 2:
                    # ë¶ˆí•„ìš”í•œ ê¸°í˜¸ë‚˜ í…ìŠ¤íŠ¸ ì œê±°
                    cleaned = re.sub(r'[â†’\-\*â€¢]', '', line)
                    cleaned = cleaned.strip()
                    # "ë¡œ ê°ì‹¸ì§„ ë¶€ë¶„ ì¶”ì¶œ
                    if '"' in cleaned:
                        match = re.search(r'"([^"]*)"', cleaned)
                        if match:
                            return match.group(1)
                    return cleaned
            
            # "+" ë¬¸ìê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ë¼ì¸ ë°˜í™˜
            return lines[0] if lines else text
            
        except Exception as e:
            print(f"âŒ ë²ˆì—­ ì‹¤íŒ¨ ({korean_text[:30]}...): {e}")
            return ""

    def calculate_jaccard_similarity(self, predicted: str, expected: str) -> float:
        """Jaccard ìœ ì‚¬ë„ ê³„ì‚°"""
        pred_words = set(predicted.split('+')) if predicted else set()
        exp_words = set(expected.split('+')) if expected else set()
        
        intersection = pred_words.intersection(exp_words)
        union = pred_words.union(exp_words)
        
        if len(union) == 0:
            return 1.0 if len(pred_words) == 0 and len(exp_words) == 0 else 0.0
        
        return len(intersection) / len(union)

    def calculate_word_accuracy(self, predicted: str, expected: str) -> Dict:
        """ë‹¨ì–´ ì •í™•ë„ ê³„ì‚°"""
        pred_words = predicted.split('+') if predicted else []
        exp_words = expected.split('+') if expected else []
        
        pred_set = set(pred_words)
        exp_set = set(exp_words)
        matching_words = len(pred_set.intersection(exp_set))
        
        if len(exp_words) == 0:
            accuracy = 1.0 if len(pred_words) == 0 else 0.0
        else:
            accuracy = matching_words / len(exp_words)
        
        return {
            "word_accuracy": accuracy,
            "predicted_words": len(pred_words),
            "expected_words": len(exp_words),
            "matching_words": matching_words
        }

    def load_test_data(self, test_file_path: str) -> List[Dict]:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ"""
        test_data = []
        
        try:
            with open(test_file_path, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    try:
                        data = json.loads(line.strip())
                        
                        korean_text = data["contents"][0]["parts"][0]["text"]
                        expected_sign = data["contents"][1]["parts"][0]["text"]
                        
                        test_data.append({
                            "index": i + 1,
                            "korean": korean_text,
                            "expected": expected_sign
                        })
                        
                    except (json.JSONDecodeError, KeyError) as e:
                        print(f"âš ï¸  ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜ (ë¼ì¸ {i+1}): {e}")
                        continue
                        
            print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(test_data)}ê°œ ìƒ˜í”Œ")
            return test_data
            
        except FileNotFoundError:
            print(f"âŒ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_file_path}")
            return []

    def evaluate_model(self, test_data: List[Dict], max_samples: int = None) -> Dict:
        """ëª¨ë¸ í‰ê°€ ì‹¤í–‰"""
        if max_samples:
            test_data = test_data[:max_samples]
        
        print(f"\nğŸ§ª ê¸°ë³¸ Gemini ëª¨ë¸ í‰ê°€ ì‹œì‘ ({len(test_data)}ê°œ ìƒ˜í”Œ)")
        print("=" * 70)
        
        results = []
        total_jaccard = 0.0
        total_word_accuracy = 0.0
        successful_tests = 0
        
        start_time = time.time()
        
        for i, sample in enumerate(test_data, 1):
            korean = sample["korean"]
            expected = sample["expected"]
            
            print(f"[{i}/{len(test_data)}] ë²ˆì—­ ì¤‘: {korean[:50]}...")
            
            # ë²ˆì—­ ì‹¤í–‰
            predicted = self.translate_to_sign(korean)
            
            if predicted:
                # ìœ ì‚¬ë„ ê³„ì‚°
                jaccard = self.calculate_jaccard_similarity(predicted, expected)
                word_acc_info = self.calculate_word_accuracy(predicted, expected)
                
                total_jaccard += jaccard
                total_word_accuracy += word_acc_info["word_accuracy"]
                successful_tests += 1
                
                # ê²°ê³¼ ì €ì¥
                result = {
                    "index": sample["index"],
                    "korean": korean,
                    "expected": expected,
                    "predicted": predicted,
                    "similarity": {
                        "jaccard": jaccard,
                        **word_acc_info
                    }
                }
                results.append(result)
                
                # ì§„í–‰ë¥  ì¶œë ¥
                if i % 5 == 0 or successful_tests <= 3:
                    avg_jaccard = total_jaccard / successful_tests
                    print(f"   âœ… ì„±ê³µ! Jaccard: {jaccard:.3f}")
                    print(f"   ì˜ˆìƒ: {expected}")
                    print(f"   ì˜ˆì¸¡: {predicted}")
                    print(f"   í˜„ì¬ í‰ê·  Jaccard: {avg_jaccard:.3f}")
            else:
                print(f"   âŒ ë²ˆì—­ ì‹¤íŒ¨")
        
        # ìµœì¢… ê²°ê³¼ ê³„ì‚°
        avg_jaccard = total_jaccard / successful_tests if successful_tests > 0 else 0.0
        avg_word_accuracy = total_word_accuracy / successful_tests if successful_tests > 0 else 0.0
        
        evaluation_result = {
            "model_name": "gemini-2.5-flash (baseline)",
            "test_time": datetime.now().isoformat(),
            "total_samples": len(test_data),
            "successful_tests": successful_tests,
            "avg_jaccard": avg_jaccard,
            "avg_word_accuracy": avg_word_accuracy,
            "detailed_results": results
        }
        
        print("\n" + "=" * 70)
        print("ğŸ‰ í‰ê°€ ì™„ë£Œ!")
        print(f"âœ… ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {successful_tests}/{len(test_data)}")
        print(f"ğŸ“Š í‰ê·  Jaccard ìœ ì‚¬ë„: {avg_jaccard:.4f}")
        print(f"ğŸ“Š í‰ê·  ë‹¨ì–´ ì •í™•ë„: {avg_word_accuracy:.4f}")
        
        return evaluation_result

    def save_results(self, results: Dict, output_file: str):
        """í‰ê°€ ê²°ê³¼ ì €ì¥"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ ê¸°ë³¸ Gemini 2.5 Flash ëª¨ë¸ í‰ê°€ (ë² ì´ìŠ¤ë¼ì¸)")
    print("=" * 70)
    
    # í”„ë¡œì íŠ¸ ì„¤ì •
    PROJECT_ID = "geminisignkorean"
    LOCATION = "us-central1"
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼
    TEST_DATA_FILE = "data/gemini_test_1pct.jsonl"
    
    # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    OUTPUT_FILE = f"data/baseline_gemini_evaluation_{timestamp}.json"
    
    try:
        # í‰ê°€ì ì´ˆê¸°í™”
        evaluator = BaselineGeminiEvaluator(PROJECT_ID, LOCATION)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        test_data = evaluator.load_test_data(TEST_DATA_FILE)
        
        if not test_data:
            print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì‚¬ìš©ì ì…ë ¥: í…ŒìŠ¤íŠ¸í•  ìƒ˜í”Œ ìˆ˜
        print(f"\nğŸ“Š ì´ {len(test_data)}ê°œì˜ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œì´ ìˆìŠµë‹ˆë‹¤.")
        sample_input = input("í…ŒìŠ¤íŠ¸í•  ìƒ˜í”Œ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì „ì²´ëŠ” Enter): ").strip()
        
        max_samples = None
        if sample_input:
            try:
                max_samples = int(sample_input)
                print(f"ğŸ“ {max_samples}ê°œ ìƒ˜í”Œë¡œ ì œí•œí•˜ì—¬ í‰ê°€í•©ë‹ˆë‹¤.")
            except ValueError:
                print("âš ï¸  ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ì „ì²´ ìƒ˜í”Œë¡œ í‰ê°€í•©ë‹ˆë‹¤.")
        
        # í‰ê°€ ì‹¤í–‰
        results = evaluator.evaluate_model(test_data, max_samples)
        
        # ê²°ê³¼ ì €ì¥
        evaluator.save_results(results, OUTPUT_FILE)
        
        print(f"\nğŸ¯ í‰ê°€ ìš”ì•½:")
        print(f"   ëª¨ë¸: ê¸°ë³¸ Gemini 2.5 Flash (ë² ì´ìŠ¤ë¼ì¸)")
        print(f"   í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {results['successful_tests']}/{results['total_samples']}")
        print(f"   Jaccard ìœ ì‚¬ë„: {results['avg_jaccard']:.4f}")
        print(f"   ë‹¨ì–´ ì •í™•ë„: {results['avg_word_accuracy']:.4f}")
        print(f"   ê²°ê³¼ íŒŒì¼: {OUTPUT_FILE}")
        
    except Exception as e:
        print(f"âŒ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main() 