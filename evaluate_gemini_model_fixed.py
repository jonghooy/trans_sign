#!/usr/bin/env python3
"""
Gemini 2.5 Flash íŒŒì¸íŠœë‹ëœ ëª¨ë¸ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ (ìˆ˜ì • ë²„ì „)

íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì˜ ë²ˆì—­ ì„±ëŠ¥ì„ Jaccard ìœ ì‚¬ë„ì™€ Word Accuracyë¡œ ì¸¡ì •í•©ë‹ˆë‹¤.
"""

import os
import json
import time
import re
from datetime import datetime
from typing import List, Dict, Tuple
import vertexai
from vertexai.generative_models import GenerativeModel, Part

class GeminiModelEvaluator:
    def __init__(self, project_id: str, location: str = "us-central1"):
        """
        Gemini ëª¨ë¸ í‰ê°€ì ì´ˆê¸°í™”
        
        Args:
            project_id: Google Cloud í”„ë¡œì íŠ¸ ID
            location: Vertex AI ì§€ì—­
        """
        self.project_id = project_id
        self.location = location
        
        # Vertex AI ì´ˆê¸°í™”
        vertexai.init(project=project_id, location=location)
        
        # íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ì •ë³´
        self.tuned_model_name = "projects/530606339865/locations/us-central1/models/1203467153647337472"
        
        # íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë¡œë“œ (ì‹œìŠ¤í…œ ì¸ìŠ¤íŠ¸ëŸ­ì…˜ í¬í•¨)
        try:
            # ì‹œìŠ¤í…œ ì¸ìŠ¤íŠ¸ëŸ­ì…˜ ì„¤ì •
            system_instruction = """ë‹¹ì‹ ì€ í•œêµ­ì–´ë¥¼ í•œêµ­ ìˆ˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 

ì£¼ì–´ì§„ í•œêµ­ì–´ ë¬¸ì¥ì„ ì •í™•í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ ìˆ˜ì–´ í‘œê¸°ë²•ìœ¼ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. 

ë²ˆì—­ ê·œì¹™:
1. ë‹¨ì–´ëŠ” '+'ë¡œ ì—°ê²°í•©ë‹ˆë‹¤
2. ê³ ìœ ëª…ì‚¬ë‚˜ ìˆ«ìëŠ” {}ë¡œ ê°ìŒ‰ë‹ˆë‹¤
3. ìˆ˜ì–´ ë¬¸ë²•ì— ë§ê²Œ ì–´ìˆœì„ ì¡°ì •í•©ë‹ˆë‹¤
4. ê°„ê²°í•˜ê³  ëª…í™•í•œ í‘œí˜„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤"""

            self.model = GenerativeModel(
                model_name=self.tuned_model_name,
                system_instruction=system_instruction
            )
            print(f"âœ… íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.tuned_model_name}")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise

    def translate_to_sign(self, korean_text: str, temperature: float = 0.1) -> str:
        """
        í•œêµ­ì–´ ë¬¸ì¥ì„ ìˆ˜ì–´ë¡œ ë²ˆì—­
        
        Args:
            korean_text: ë²ˆì—­í•  í•œêµ­ì–´ ë¬¸ì¥
            temperature: ìƒì„± ì˜¨ë„ (ê¸°ë³¸ê°’: 0.1)
            
        Returns:
            ìˆ˜ì–´ ë²ˆì—­ ê²°ê³¼
        """
        try:
            # ìƒì„± ì„¤ì •
            generation_config = {
                "temperature": temperature,
                "max_output_tokens": 200,
                "top_p": 0.8,
                "top_k": 40
            }
            
            response = self.model.generate_content(
                korean_text,
                generation_config=generation_config
            )
            
            return response.text.strip()
            
        except Exception as e:
            print(f"âŒ ë²ˆì—­ ì‹¤íŒ¨ ({korean_text[:30]}...): {e}")
            return ""

    def calculate_jaccard_similarity(self, predicted: str, expected: str) -> float:
        """
        Jaccard ìœ ì‚¬ë„ ê³„ì‚°
        
        Args:
            predicted: ì˜ˆì¸¡ëœ ë²ˆì—­ ê²°ê³¼
            expected: ê¸°ëŒ€ë˜ëŠ” ë²ˆì—­ ê²°ê³¼
            
        Returns:
            Jaccard ìœ ì‚¬ë„ (0.0 ~ 1.0)
        """
        # '+'ë¡œ ë¶„í• í•˜ì—¬ ë‹¨ì–´ ì§‘í•© ìƒì„±
        pred_words = set(predicted.split('+')) if predicted else set()
        exp_words = set(expected.split('+')) if expected else set()
        
        # êµì§‘í•©ê³¼ í•©ì§‘í•© ê³„ì‚°
        intersection = pred_words.intersection(exp_words)
        union = pred_words.union(exp_words)
        
        # Jaccard ìœ ì‚¬ë„ = |êµì§‘í•©| / |í•©ì§‘í•©|
        if len(union) == 0:
            return 1.0 if len(pred_words) == 0 and len(exp_words) == 0 else 0.0
        
        return len(intersection) / len(union)

    def calculate_word_accuracy(self, predicted: str, expected: str) -> Dict:
        """
        ë‹¨ì–´ ì •í™•ë„ ê³„ì‚°
        
        Args:
            predicted: ì˜ˆì¸¡ëœ ë²ˆì—­ ê²°ê³¼
            expected: ê¸°ëŒ€ë˜ëŠ” ë²ˆì—­ ê²°ê³¼
            
        Returns:
            ë‹¨ì–´ ì •í™•ë„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        pred_words = predicted.split('+') if predicted else []
        exp_words = expected.split('+') if expected else []
        
        # êµì§‘í•© ê³„ì‚° (ìˆœì„œ ë¬´ê´€)
        pred_set = set(pred_words)
        exp_set = set(exp_words)
        matching_words = len(pred_set.intersection(exp_set))
        
        # ì •í™•ë„ ê³„ì‚°
        if len(exp_words) == 0:
            accuracy = 1.0 if len(pred_words) == 0 else 0.0
        else:
            accuracy = matching_words / len(exp_words)
        
        return {
            "word_accuracy": accuracy,
            "predicted_words": len(pred_words),
            "expected_words": len(exp_words),
            "matching_words": matching_words
        }

    def load_test_data(self, test_file_path: str) -> List[Dict]:
        """
        í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        
        Args:
            test_file_path: í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ ê²½ë¡œ (JSONL)
            
        Returns:
            í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        test_data = []
        
        try:
            with open(test_file_path, 'r', encoding='utf-8') as f:
                for i, line in enumerate(f):
                    try:
                        data = json.loads(line.strip())
                        
                        # Gemini í˜•ì‹ì—ì„œ í•œêµ­ì–´ì™€ ìˆ˜ì–´ ì¶”ì¶œ
                        korean_text = data["contents"][0]["parts"][0]["text"]
                        expected_sign = data["contents"][1]["parts"][0]["text"]
                        
                        test_data.append({
                            "index": i + 1,
                            "korean": korean_text,
                            "expected": expected_sign
                        })
                        
                    except (json.JSONDecodeError, KeyError) as e:
                        print(f"âš ï¸  ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜ (ë¼ì¸ {i+1}): {e}")
                        continue
                        
            print(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(test_data)}ê°œ ìƒ˜í”Œ")
            return test_data
            
        except FileNotFoundError:
            print(f"âŒ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_file_path}")
            return []

    def evaluate_sample(self, korean: str, expected: str) -> Dict:
        """ë‹¨ì¼ ìƒ˜í”Œ í‰ê°€"""
        predicted = self.translate_to_sign(korean)
        
        if predicted:
            jaccard = self.calculate_jaccard_similarity(predicted, expected)
            word_acc_info = self.calculate_word_accuracy(predicted, expected)
            
            return {
                "success": True,
                "predicted": predicted,
                "jaccard": jaccard,
                "word_accuracy": word_acc_info["word_accuracy"],
                "word_info": word_acc_info
            }
        else:
            return {
                "success": False,
                "predicted": "",
                "jaccard": 0.0,
                "word_accuracy": 0.0,
                "word_info": {}
            }

    def evaluate_model(self, test_data: List[Dict], max_samples: int = None) -> Dict:
        """
        ëª¨ë¸ í‰ê°€ ì‹¤í–‰
        
        Args:
            test_data: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            max_samples: ìµœëŒ€ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜ (Noneì´ë©´ ì „ì²´)
            
        Returns:
            í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if max_samples:
            test_data = test_data[:max_samples]
        
        print(f"\nğŸ§ª ëª¨ë¸ í‰ê°€ ì‹œì‘ ({len(test_data)}ê°œ ìƒ˜í”Œ)")
        print("=" * 70)
        
        results = []
        total_jaccard = 0.0
        total_word_accuracy = 0.0
        successful_tests = 0
        
        start_time = time.time()
        
        for i, sample in enumerate(test_data, 1):
            korean = sample["korean"]
            expected = sample["expected"]
            
            print(f"[{i}/{len(test_data)}] ë²ˆì—­ ì¤‘: {korean[:50]}...")
            
            # ë²ˆì—­ ë° í‰ê°€ ì‹¤í–‰
            eval_result = self.evaluate_sample(korean, expected)
            
            if eval_result["success"]:
                total_jaccard += eval_result["jaccard"]
                total_word_accuracy += eval_result["word_accuracy"]
                successful_tests += 1
                
                # ê²°ê³¼ ì €ì¥
                result = {
                    "index": sample["index"],
                    "korean": korean,
                    "expected": expected,
                    "predicted": eval_result["predicted"],
                    "similarity": {
                        "jaccard": eval_result["jaccard"],
                        **eval_result["word_info"]
                    }
                }
                results.append(result)
                
                # ì§„í–‰ë¥  ì¶œë ¥
                if i % 10 == 0 or successful_tests <= 5:
                    elapsed = time.time() - start_time
                    avg_jaccard = total_jaccard / successful_tests
                    print(f"   âœ… ì„±ê³µ! Jaccard: {eval_result['jaccard']:.3f}")
                    print(f"   ì§„í–‰ë¥ : {i}/{len(test_data)} ({i/len(test_data)*100:.1f}%)")
                    print(f"   í˜„ì¬ í‰ê·  Jaccard: {avg_jaccard:.3f}")
                    print(f"   ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")
            else:
                print(f"   âŒ ë²ˆì—­ ì‹¤íŒ¨")
        
        # ìµœì¢… ê²°ê³¼ ê³„ì‚°
        avg_jaccard = total_jaccard / successful_tests if successful_tests > 0 else 0.0
        avg_word_accuracy = total_word_accuracy / successful_tests if successful_tests > 0 else 0.0
        
        evaluation_result = {
            "model_name": self.tuned_model_name,
            "test_time": datetime.now().isoformat(),
            "total_samples": len(test_data),
            "successful_tests": successful_tests,
            "avg_jaccard": avg_jaccard,
            "avg_word_accuracy": avg_word_accuracy,
            "detailed_results": results
        }
        
        print("\n" + "=" * 70)
        print("ğŸ‰ í‰ê°€ ì™„ë£Œ!")
        print(f"âœ… ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {successful_tests}/{len(test_data)}")
        print(f"ğŸ“Š í‰ê·  Jaccard ìœ ì‚¬ë„: {avg_jaccard:.4f}")
        print(f"ğŸ“Š í‰ê·  ë‹¨ì–´ ì •í™•ë„: {avg_word_accuracy:.4f}")
        
        return evaluation_result

    def save_results(self, results: Dict, output_file: str):
        """í‰ê°€ ê²°ê³¼ ì €ì¥"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        except Exception as e:
            print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Gemini 2.5 Flash íŒŒì¸íŠœë‹ëœ ëª¨ë¸ í‰ê°€ (ìˆ˜ì • ë²„ì „)")
    print("=" * 70)
    
    # í”„ë¡œì íŠ¸ ì„¤ì •
    PROJECT_ID = "geminisignkorean"
    LOCATION = "us-central1"
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼
    TEST_DATA_FILE = "data/gemini_test_1pct.jsonl"
    
    # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    OUTPUT_FILE = f"data/gemini_evaluation_fixed_{timestamp}.json"
    
    try:
        # í‰ê°€ì ì´ˆê¸°í™”
        evaluator = GeminiModelEvaluator(PROJECT_ID, LOCATION)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        test_data = evaluator.load_test_data(TEST_DATA_FILE)
        
        if not test_data:
            print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì‚¬ìš©ì ì…ë ¥: í…ŒìŠ¤íŠ¸í•  ìƒ˜í”Œ ìˆ˜
        print(f"\nğŸ“Š ì´ {len(test_data)}ê°œì˜ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œì´ ìˆìŠµë‹ˆë‹¤.")
        sample_input = input("í…ŒìŠ¤íŠ¸í•  ìƒ˜í”Œ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì „ì²´ëŠ” Enter): ").strip()
        
        max_samples = None
        if sample_input:
            try:
                max_samples = int(sample_input)
                print(f"ğŸ“ {max_samples}ê°œ ìƒ˜í”Œë¡œ ì œí•œí•˜ì—¬ í‰ê°€í•©ë‹ˆë‹¤.")
            except ValueError:
                print("âš ï¸  ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ì „ì²´ ìƒ˜í”Œë¡œ í‰ê°€í•©ë‹ˆë‹¤.")
        
        # í‰ê°€ ì‹¤í–‰
        results = evaluator.evaluate_model(test_data, max_samples)
        
        # ê²°ê³¼ ì €ì¥
        evaluator.save_results(results, OUTPUT_FILE)
        
        print(f"\nğŸ¯ í‰ê°€ ìš”ì•½:")
        print(f"   ëª¨ë¸: Gemini 2.5 Flash (Fine-tuned)")
        print(f"   í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {results['successful_tests']}/{results['total_samples']}")
        print(f"   Jaccard ìœ ì‚¬ë„: {results['avg_jaccard']:.4f}")
        print(f"   ë‹¨ì–´ ì •í™•ë„: {results['avg_word_accuracy']:.4f}")
        print(f"   ê²°ê³¼ íŒŒì¼: {OUTPUT_FILE}")
        
    except Exception as e:
        print(f"âŒ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main() 